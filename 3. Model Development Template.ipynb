{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13331a17-f6ba-4890-ba5c-8367ff310fc7",
   "metadata": {},
   "source": [
    "# Georgia Tech Summer 2025 MSA Practicum Project\n",
    "\n",
    "### 3. Model Development Template\n",
    "\n",
    "**Hosted on [Hypertrial.ai](https://www.hypertrial.ai/university-projects/georgia-tech)**\n",
    "\n",
    "---\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hypertrial/stacking_sats_challenge/blob/main/tutorials/4.%20Strategy%20Development%20Template.ipynb)\n",
    "\n",
    "A youtube walkthrough of similar code but with different global variables can useful to watch:\n",
    "\n",
    "[![YouTube](https://img.shields.io/badge/Watch%20on-YouTube-red?logo=youtube&logoColor=white)](https://youtu.be/qJp8W83f3Fw?si=Wzo8ORKwFLHhBoM0)\n",
    "\n",
    "This notebook replicates the structure used by the evaluation engine to test all submitted strategies.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… What Youâ€™ll Learn\n",
    "\n",
    "By the end of this tutorial, you will:\n",
    "\n",
    "- Understand the **boilerplate code** and what is already provided (e.g. imports, data loading, global config)\n",
    "- Learn where and how to **insert your own strategy logic**\n",
    "- Run **backtests and visualizations** to debug and assess performance\n",
    "- Ensure your submission is **valid, testable, and reproducible**\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ What Youâ€™re Expected to Do\n",
    "\n",
    "- **Modify only the user code** inside the provided cell  \n",
    "- Leave all boilerplate (e.g. registration, config, data loading) unchanged\n",
    "- Submit your user code cell for evaluation on [Hypertrial.ai]('https://www.hypertrial.ai/')\n",
    "\n",
    "This structure guarantees consistency, fairness, and ease of comparison across all submitted models.\n",
    "\n",
    "---\n",
    "\n",
    "> âš ï¸ Do not change function names, decorators, or global config values unless explicitly allowed.  \n",
    "> Your entry must adhere to this template to be considered valid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174e7157-8631-44e3-a1d8-6b0026fe62f9",
   "metadata": {},
   "source": [
    "### ğŸš« Boilerplate Code â€” Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8715bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# core/config.py\n",
    "# ---------------------------\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Global Variables   â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "BACKTEST_START = '2020-01-01' \n",
    "BACKTEST_END = '2024-12-31'\n",
    "CYCLE_YEARS = 1 # Investment Duration (calendar years from BACKTEST_START to BACKTEST_END)  \n",
    "PURCHASE_FREQ = 'Daily' # Yet to be added in code \n",
    "MIN_WEIGHT = 1e-5 # PURCHASE_FREQ minimum investment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cf5720-52f6-4223-a7cc-12a839135007",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zn/3r5r5myd1dq34m6jv1g5rq7m0000gn/T/ipykernel_3419/4179518580.py:32: DtypeWarning: Columns (147) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  btc_df = pd.read_csv(StringIO(response.text))\n"
     ]
    }
   ],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# Extract BTC data from CoinMetrics and save locally\n",
    "# ---------------------------\n",
    "import pandas as pd \n",
    "import logging\n",
    "from datetime import datetime\n",
    "import requests # new import \n",
    "from io import StringIO # new import\n",
    "\n",
    "try:\n",
    "    from coinmetrics.api_client import CoinMetricsClient\n",
    "except ImportError:\n",
    "    raise ImportError(\"coinmetrics.api_client module is required. Install it via pip:\\n\\n    pip install coinmetrics-api-client\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "def extract_btc_data_to_csv(local_path='btc_data.csv'):\n",
    "    # Coin Metrics BTC CSV (raw GitHub URL)\n",
    "    url = \"https://raw.githubusercontent.com/coinmetrics/data/master/csv/btc.csv\"\n",
    "    \n",
    "    # Download the content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # raises an error for bad responses\n",
    "    \n",
    "    # Parse CSV content\n",
    "    btc_df = pd.read_csv(StringIO(response.text))\n",
    "\n",
    "    btc_df['time'] = pd.to_datetime(btc_df['time']).dt.normalize()\n",
    "    btc_df['time'] = btc_df['time'].dt.tz_localize(None)\n",
    "    btc_df.set_index('time', inplace=True)\n",
    "\n",
    "    btc_df.to_csv(local_path)\n",
    "    \n",
    "    # Show the df\n",
    "    btc_df\n",
    "\n",
    "btc_df = extract_btc_data_to_csv(\"btc_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ae1a569",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'btc_price_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 28\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndex must be datetime.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Global Variable to use later\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[0;32mIn[5], line 16\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_data\u001b[39m():\n\u001b[0;32m---> 16\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbtc_price_data.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;241m~\u001b[39mdf\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mduplicated(keep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlast\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     18\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_index()\n",
      "File \u001b[0;32m~/miniconda3/envs/stacking-sats-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stacking-sats-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/stacking-sats-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/stacking-sats-env/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/stacking-sats-env/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'btc_price_data.csv'"
     ]
    }
   ],
   "source": [
    "# ğŸš« DO NOT MODIFY: Framework boilerplate cell\n",
    "# ---------------------------\n",
    "# core/data.py\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(\n",
    "    format='%(asctime)s %(levelname)-8s %(message)s',\n",
    "    level=logging.INFO,\n",
    "    datefmt='%Y-%m-%d %H:%M:%S'\n",
    ")\n",
    "\n",
    "def load_data():\n",
    "    df = pd.read_csv(\"btc_data.csv\", index_col=0, parse_dates=True)\n",
    "    df = df.loc[~df.index.duplicated(keep='last')]\n",
    "    df = df.sort_index()\n",
    "    return df\n",
    "\n",
    "def validate_price_data(df):\n",
    "    if df.empty or 'PriceUSD' not in df.columns:\n",
    "        raise ValueError(\"Invalid BTC price data.\")\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise ValueError(\"Index must be datetime.\")\n",
    "\n",
    "# Global Variable to use later\n",
    "df = load_data() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0861931f-ca58-4af4-9d2d-b4a113a7526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# core/spd.py\n",
    "# ---------------------------\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Imports    â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  Main helpers â€“ cycle length driven by CYCLE_YEARS â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "def _make_cycle_label(start, end, cycle_years):\n",
    "    \"\"\"Return a pretty label for a cycle of arbitrary length.\"\"\"\n",
    "    if cycle_years == 1:\n",
    "        return f\"{start.year}\"\n",
    "    return f\"{start.year}â€“{end.year}\"\n",
    "\n",
    "\n",
    "def compute_cycle_spd(df, strategy_fn, *, cycle_years: int = CYCLE_YEARS):\n",
    "    \"\"\"\n",
    "    Compute SPD stats per cycle of length `cycle_years`.\n",
    "    \"\"\"\n",
    "    df_backtest = df.loc[BACKTEST_START:BACKTEST_END]\n",
    "    cycle_length = pd.DateOffset(years=cycle_years)\n",
    "\n",
    "    current = df_backtest.index.min()\n",
    "    rows = []\n",
    "\n",
    "    full_weights = strategy_fn(df)#.fillna(0).clip(lower=0)\n",
    "    inverted_prices = (1 / df_backtest[\"PriceUSD\"]) * 1e8  # satoshi-per-dollar\n",
    "\n",
    "    while current <= df_backtest.index.max():\n",
    "        cycle_end = current + cycle_length - pd.Timedelta(days=1)\n",
    "        end_date = min(cycle_end, df_backtest.index.max())\n",
    "\n",
    "        cycle_mask = (df_backtest.index >= current) & (df_backtest.index <= end_date)\n",
    "        cycle = df_backtest.loc[cycle_mask]\n",
    "        if cycle.empty:\n",
    "            break\n",
    "\n",
    "        #label = _plot_cycle_label(current, cycle_years)\n",
    "        label = _make_cycle_label(current, end_date, cycle_years)\n",
    "\n",
    "        prices = cycle[\"PriceUSD\"].values\n",
    "        high, low = np.max(prices), np.min(prices)\n",
    "        min_spd, max_spd = (1 / high) * 1e8, (1 / low) * 1e8\n",
    "\n",
    "        cycle_inv = inverted_prices.loc[cycle.index]\n",
    "        w_slice = full_weights.loc[cycle.index]\n",
    "\n",
    "        dynamic_spd = (w_slice * cycle_inv).sum()\n",
    "        uniform_spd = cycle_inv.mean()\n",
    "\n",
    "        spd_range = max_spd - min_spd\n",
    "        uniform_pct = (uniform_spd - min_spd) / spd_range * 100\n",
    "        dynamic_pct = (dynamic_spd - min_spd) / spd_range * 100\n",
    "        excess_pct = dynamic_pct - uniform_pct\n",
    "\n",
    "        rows.append(\n",
    "            {\n",
    "                \"cycle\": label,\n",
    "                \"min_spd\": min_spd,\n",
    "                \"max_spd\": max_spd,\n",
    "                \"uniform_spd\": uniform_spd,\n",
    "                \"dynamic_spd\": dynamic_spd,\n",
    "                \"uniform_pct\": uniform_pct,\n",
    "                \"dynamic_pct\": dynamic_pct,\n",
    "                \"excess_pct\": excess_pct,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        current += cycle_length\n",
    "\n",
    "    return pd.DataFrame(rows).set_index(\"cycle\")\n",
    "\n",
    "\n",
    "def backtest_dynamic_dca(\n",
    "    df, strategy_fn, *, strategy_label: str = \"your_strategy\", cycle_years: int = CYCLE_YEARS\n",
    "):\n",
    "    \"\"\"\n",
    "    Convenience wrapper: print aggregate stats and return the cycle table.\n",
    "    \"\"\"\n",
    "    res = compute_cycle_spd(df, strategy_fn, cycle_years=cycle_years)\n",
    "\n",
    "    dyn_spd = res[\"dynamic_spd\"]\n",
    "    dyn_pct = res[\"dynamic_pct\"]\n",
    "\n",
    "    print(f\"\\nAggregated Metrics for {strategy_label}:\")\n",
    "    print(\"Dynamic SPD:\")\n",
    "    for k in [\"min\", \"max\", \"mean\", \"median\"]:\n",
    "        print(f\"  {k}: {getattr(dyn_spd, k)():.2f}\")\n",
    "    print(\"Dynamic SPD Percentile:\")\n",
    "    for k in [\"min\", \"max\", \"mean\", \"median\"]:\n",
    "        print(f\"  {k}: {getattr(dyn_pct, k)():.2f}\")\n",
    "\n",
    "    print(\"\\nExcess SPD Percentile Difference (Dynamic â€“ Uniform) per Cycle:\")\n",
    "    for cycle, row in res.iterrows():\n",
    "        print(f\"  {cycle}: {row['excess_pct']:.2f}%\")\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def check_strategy_submission_ready(\n",
    "    df, strategy_fn, *, cycle_years: int = CYCLE_YEARS\n",
    "):\n",
    "    \"\"\"\n",
    "    Sanity-check that a strategy:\n",
    "      â€¢ has strictly positive weights â‰¥ MIN_WEIGHT\n",
    "      â€¢ weights per cycle sum â‰ˆ 1\n",
    "      â€¢ beats uniform DCA on SPD percentile\n",
    "    \"\"\"\n",
    "    df_backtest = df.loc[BACKTEST_START:BACKTEST_END]\n",
    "    cycle_length = pd.DateOffset(years=cycle_years)\n",
    "\n",
    "    current = df_backtest.index.min()\n",
    "    full_weights = strategy_fn(df).fillna(0)\n",
    "\n",
    "    passed = True\n",
    "\n",
    "    # TODO: Add forward looking check \n",
    "        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # ğŸ” Forward-looking leakage check\n",
    "    #    -------------------------------------------------------------\n",
    "    #    For ~50 evenly-spaced dates we recompute the strategy with\n",
    "    #    *all* future data blanked-out (set to NaN).  If the weight\n",
    "    #    for the probe date moves, the model must have looked ahead.\n",
    "    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # pick at most 50 probe dates, evenly spaced through the back-test\n",
    "    step        = max(len(df_backtest) // 50, 1)\n",
    "    probe_dates = df_backtest.index[::step]\n",
    "\n",
    "    for probe in probe_dates:\n",
    "        df_masked = df.copy()\n",
    "        # hide every feature value that would only be known *after* probe\n",
    "        df_masked.loc[df_masked.index > probe, :] = np.nan\n",
    "\n",
    "        masked_w  = strategy_fn(df_masked).reindex_like(full_weights).fillna(0)\n",
    "\n",
    "        # compare the two versions for the probe date\n",
    "        if not np.isclose(masked_w.loc[probe], full_weights.loc[probe],\n",
    "                          rtol=1e-9, atol=1e-12):\n",
    "            print(\n",
    "                f\"[{probe.date()}] âŒ Forward-looking data detected â€“ \"\n",
    "                f\"weight differs when future is masked \"\n",
    "                f\"(Î” = {abs(masked_w.loc[probe]-full_weights.loc[probe]):.2e}).\"\n",
    "            )\n",
    "            passed = False\n",
    "            break\n",
    "\n",
    "    while current <= df_backtest.index.max():\n",
    "        cycle_end = current + cycle_length - pd.Timedelta(days=1)\n",
    "        end_date = min(cycle_end, df_backtest.index.max())\n",
    "\n",
    "        label = _make_cycle_label(current, end_date, cycle_years)\n",
    "\n",
    "        mask = (df_backtest.index >= current) & (df_backtest.index <= end_date)\n",
    "        w_slice = full_weights.loc[df_backtest.loc[mask].index]\n",
    "\n",
    "        if (w_slice <= 0).any():\n",
    "            print(f\"[{label}] âŒ Some weights are zero or negative.\")\n",
    "            passed = False\n",
    "\n",
    "        if (w_slice < MIN_WEIGHT).any():\n",
    "            print(f\"[{label}] âŒ Some weights are below MIN_WEIGHT = {MIN_WEIGHT}.\")\n",
    "            passed = False\n",
    "\n",
    "        tot_wt = w_slice.sum().sum() if isinstance(w_slice, pd.DataFrame) else w_slice.sum()\n",
    "        if not np.isclose(tot_wt, 1.0, rtol=1e-5, atol=1e-8):\n",
    "            print(f\"[{label}] âŒ Total weights do not sum to 1 (sum = {tot_wt:.6f}).\")\n",
    "            passed = False\n",
    "\n",
    "        current += cycle_length\n",
    "\n",
    "    spd_res = compute_cycle_spd(df, strategy_fn, cycle_years=cycle_years)\n",
    "    for cycle, row in spd_res.iterrows():\n",
    "        if row[\"dynamic_pct\"] < row[\"uniform_pct\"]:\n",
    "            print(\n",
    "                f\"[{cycle}] âŒ Dynamic SPD percentile ({row['dynamic_pct']:.2f}%) \"\n",
    "                f\"is less than uniform ({row['uniform_pct']:.2f}%).\"\n",
    "            )\n",
    "            passed = False\n",
    "\n",
    "    print(\"âœ… Strategy is ready for submission.\" if passed else \"âš ï¸ Fix issues above.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ace4ddc-5f14-470e-bf55-f3a723c37bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# core/plots.py\n",
    "# ---------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# helpers\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "def _plot_cycle_label(start_year: int, cycle_idx: int) -> str:\n",
    "    \"\"\"\n",
    "    Pretty cycle label for arbitrary cycle length.\n",
    "    \"\"\"\n",
    "    first = start_year + CYCLE_YEARS * cycle_idx\n",
    "    if CYCLE_YEARS == 1:\n",
    "        return f\"{first}\"\n",
    "    return f\"{first}â€“{first + CYCLE_YEARS - 1}\"\n",
    "\n",
    "\n",
    "def _cycle_idx(timestamp, start_year):\n",
    "    \"\"\"\n",
    "    Integer cycle index for a timestamp relative to the first back-test year.\n",
    "    \"\"\"\n",
    "    return (timestamp.year - start_year) // CYCLE_YEARS\n",
    "\n",
    "\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# plotting utilities\n",
    "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "\n",
    "def plot_features(\n",
    "    df,\n",
    "    weights=None,\n",
    "    *,\n",
    "    start_date: str | pd.Timestamp = BACKTEST_START,\n",
    "    end_date: str | pd.Timestamp = BACKTEST_END,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot BTC price vs. the first derived feature within the chosen back-test window.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Raw BTC price dataframe (`PriceUSD` must be present).\n",
    "    weights : pd.Series or None, optional\n",
    "        Daily weight series aligned on the same index as `df` (used only for\n",
    "        marker styling). If provided, it is automatically trimmed to the same\n",
    "        date window.\n",
    "    start_date, end_date : str or pd.Timestamp, optional\n",
    "        Window to plot.  Defaults to BACKTEST_START / BACKTEST_END from config.\n",
    "    \"\"\"\n",
    "    # Build features first, then trim to the requested window\n",
    "    df = construct_features(df).loc[start_date:end_date]\n",
    "\n",
    "    # Trim weights (if any) to the same index\n",
    "    if weights is not None:\n",
    "        weights = weights.loc[df.index]\n",
    "\n",
    "    feature_name = df.columns[1]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "    ax.set_title(f\"BTC Price and {feature_name}\")\n",
    "    ax.set_xlabel(\"Date\")\n",
    "    ax.set_ylabel(\"Value\")\n",
    "\n",
    "    # Main series\n",
    "    ax.plot(df.index, df[\"PriceUSD\"], label=\"BTC Price\", color=\"black\", alpha=0.7)\n",
    "    ax.plot(df.index, df[feature_name], label=feature_name, color=\"orange\", alpha=0.7)\n",
    "\n",
    "    # Highlight regions where the feature value exceeds price\n",
    "    signal = df[\"PriceUSD\"] < df[feature_name]\n",
    "    ax.fill_between(\n",
    "        df.index,\n",
    "        df[\"PriceUSD\"],\n",
    "        df[feature_name],\n",
    "        where=signal,\n",
    "        color=\"green\",\n",
    "        alpha=0.1,\n",
    "    )\n",
    "\n",
    "    # Optional weight markers (colour-coded by the same signal for now)\n",
    "    if weights is not None:\n",
    "        ax.scatter(\n",
    "            df.index[~signal],\n",
    "            df.loc[~signal, \"PriceUSD\"],\n",
    "            marker=\"o\",\n",
    "            facecolors=\"none\",\n",
    "            edgecolors=\"blue\",\n",
    "            label=\"Uniform\",\n",
    "        )\n",
    "        ax.scatter(\n",
    "            df.index[signal],\n",
    "            df.loc[signal, \"PriceUSD\"],\n",
    "            marker=\"o\",\n",
    "            color=\"red\",\n",
    "            label=\"Dynamic\",\n",
    "        )\n",
    "\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_final_weights(\n",
    "    weights: pd.Series,\n",
    "    *,\n",
    "    start_date: str | pd.Timestamp = BACKTEST_START,\n",
    "    cycle_years: int = CYCLE_YEARS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot daily position weights with one curve per investment cycle and show\n",
    "    a horizontal dashed line at the global MIN_WEIGHT threshold.\n",
    "    \"\"\"\n",
    "    # â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def _cycle_idx(ts, first_year):\n",
    "        return (ts.year - first_year) // cycle_years\n",
    "\n",
    "    def _cycle_label(first_year, idx):\n",
    "        first = first_year + cycle_years * idx\n",
    "        return f\"{first}\" if cycle_years == 1 else f\"{first}â€“{first + cycle_years - 1}\"\n",
    "\n",
    "    # â”€â”€ compute cycle labels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    start_year = pd.to_datetime(start_date).year\n",
    "    cycle_indices = weights.index.to_series().apply(lambda dt: _cycle_idx(dt, start_year))\n",
    "\n",
    "    # â”€â”€ plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "    fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "    for idx, group in weights.groupby(cycle_indices):\n",
    "        label = _cycle_label(start_year, idx)\n",
    "        ax.plot(group.index, group.values, label=label, color=cmap(idx % 10))\n",
    "\n",
    "        # per-cycle uniform weight baseline\n",
    "        uniform = 1.0 / len(group)\n",
    "        ax.hlines(\n",
    "            uniform,\n",
    "            group.index.min(),\n",
    "            group.index.max(),\n",
    "            color=cmap(idx % 10),\n",
    "            linestyle=\"--\",\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "    # global MIN_WEIGHT threshold (one line across the whole plot)\n",
    "    ax.axhline(\n",
    "        MIN_WEIGHT,\n",
    "        color=\"black\",\n",
    "        linestyle=\"--\",\n",
    "        linewidth=1,\n",
    "        label=f\"MIN_WEIGHT = {MIN_WEIGHT:g}\",\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Final Daily Weights\")\n",
    "    \n",
    "    labels = list(weights.groupby(cycle_indices).groups.keys())\n",
    "    n_labels = len(labels) + 1  # +1 for MIN_WEIGHT line\n",
    "    \n",
    "    ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, 1.00),\n",
    "        ncol=n_labels,\n",
    "        fontsize=\"small\",\n",
    "        frameon=True,\n",
    "        handlelength=1.5,\n",
    "        columnspacing=1.2\n",
    "    )\n",
    "\n",
    "\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_weight_sums_by_cycle(\n",
    "    weights,\n",
    "    *,\n",
    "    start_date: str | pd.Timestamp = BACKTEST_START,\n",
    "    cycle_years: int = CYCLE_YEARS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Bar-plot showing the sum of daily weights inside each investment cycle.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : pd.Series\n",
    "        Daily weight series indexed by date.\n",
    "    start_date : str or pd.Timestamp, optional\n",
    "        First day of the back-test (default = BACKTEST_START).\n",
    "    cycle_years : int, optional\n",
    "        Length of each investment cycle (default = CYCLE_YEARS).\n",
    "    \"\"\"\n",
    "    # â”€â”€ helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def _cycle_idx(ts, first_year):\n",
    "        return (ts.year - first_year) // cycle_years\n",
    "\n",
    "    def _cycle_label(first_year, idx):\n",
    "        first = first_year + cycle_years * idx\n",
    "        return f\"{first}\" if cycle_years == 1 else f\"{first}â€“{first + cycle_years - 1}\"\n",
    "\n",
    "    # â”€â”€ aggregate sums â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    start_year = pd.to_datetime(start_date).year\n",
    "    cycle_indices = weights.index.to_series().apply(lambda dt: _cycle_idx(dt, start_year))\n",
    "    weight_sums = weights.groupby(cycle_indices).sum()\n",
    "\n",
    "    # â”€â”€ console printout â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"Cycle Weight Sums:\")\n",
    "    for idx, total in weight_sums.items():\n",
    "        print(f\"  {_cycle_label(start_year, idx)}: {total:.4f}\")\n",
    "\n",
    "    # â”€â”€ plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    labels = [_cycle_label(start_year, idx) for idx in weight_sums.index]\n",
    "    plt.bar(labels, weight_sums.values, alpha=0.7)\n",
    "    plt.axhline(1.0, linestyle=\"--\", color=\"black\", label=\"Target: 1.0\")\n",
    "    plt.title(\"Weight Sums by Cycle\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_spd_comparison(\n",
    "    df_res: pd.DataFrame,\n",
    "    strategy_name: str = \"Dynamic\",\n",
    "    *,\n",
    "    cycle_years: int = CYCLE_YEARS,\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare uniform vs. dynamic DCA in sats-per-dollar space and percentile space.\n",
    "    \"\"\"\n",
    "    x = np.arange(len(df_res))\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    ax1.set_yscale(\"log\")\n",
    "\n",
    "    # â”€â”€ SPD curves in desired order: max â–¸ dynamic â–¸ uniform â–¸ min â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    lines = ax1.plot(\n",
    "        x, df_res[\"max_spd\"],     \"o-\",\n",
    "        x, df_res[\"dynamic_spd\"], \"o-\",\n",
    "        x, df_res[\"uniform_spd\"], \"o-\",\n",
    "        x, df_res[\"min_spd\"],     \"o-\",\n",
    "    )\n",
    "\n",
    "    ax1.set_title(f\"Uniform vs {strategy_name} DCA (SPD)\")\n",
    "    ax1.set_ylabel(\"Sats per Dollar (log scale)\")\n",
    "    ax1.set_xlabel(\"Cycle\" if cycle_years == 1 else f\"Cycle ({cycle_years}-yr)\")\n",
    "    ax1.grid(True, linestyle=\"--\", linewidth=0.5)\n",
    "\n",
    "    ax1.legend(\n",
    "        lines,\n",
    "        [\"Max spd (Low)\", strategy_name, \"Uniform DCA spd\", \"Min spd (High)\"],\n",
    "        loc=\"upper left\",\n",
    "    )\n",
    "\n",
    "    ax1.set_xticks(x)\n",
    "    ax1.set_xticklabels(df_res.index, rotation=15, ha=\"right\")\n",
    "\n",
    "    # â”€â”€ Percentile bars â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    ax2 = ax1.twinx()\n",
    "    bar_w = 0.4\n",
    "    bar1  = ax2.bar(x - bar_w / 2, df_res[\"uniform_pct\"],  width=bar_w, alpha=0.3)\n",
    "    bar2  = ax2.bar(x + bar_w / 2, df_res[\"dynamic_pct\"], width=bar_w, alpha=0.3)\n",
    "\n",
    "    ax2.set_ylabel(\"SPD Percentile (%)\")\n",
    "    ax2.set_ylim(0, 100)\n",
    "    ax2.legend([bar1, bar2], [\"Uniform %\", f\"{strategy_name} %\"], loc=\"upper right\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a88e94-246d-404d-9443-39790d9d5532",
   "metadata": {},
   "source": [
    "# âœï¸ User Code â€” Implement Your Strategy Logic Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538a2ca3-158c-41c3-937a-8e331b72da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "#from core.config import BACKTEST_START, BACKTEST_END, MIN_WEIGHT\n",
    "#from core.strategies import register_strategy\n",
    "\n",
    "def construct_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Construct technical indicators used for the strategy.\n",
    "    Uses only past data for calculations to avoid look-ahead bias.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with price data\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with added technical indicators\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Extract relevant features (using only price here) \n",
    "    df = df[['PriceUSD']]\n",
    "    \n",
    "    # Shift the PriceUSD column by one to use only past data for our calculations\n",
    "    past_price = df['PriceUSD'].shift(1)\n",
    "    # Calculate 200-day moving average\n",
    "    df['ma200'] = past_price.rolling(window=200, min_periods=1).mean()\n",
    "    # Calculate 200-day standard deviation\n",
    "    df['std200'] = past_price.rolling(window=200, min_periods=1).std()\n",
    "    return df\n",
    "\n",
    "# Example Ethereum wallet address - replace with real one for actual submissions\n",
    "#ETH_WALLET_ADDRESS = \"0x71C7656EC7ab88b098defB751B7401B5f6d8976F\"\n",
    "\n",
    "#@register_strategy(ETH_WALLET_ADDRESS)\n",
    "def compute_weights(df: pd.DataFrame) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Computes daily DCA weights with a 200-day moving average strategy.\n",
    "    Increases weight on days when price is below MA, redistributing from future days.\n",
    "    \n",
    "    Strategy logic:\n",
    "    1. Start with uniform weights across each market cycle\n",
    "    2. For days when price < 200MA, boost weight proportional to distance below MA\n",
    "    3. Redistribute the excess weight from future days within a rebalance window\n",
    "    4. Maintain minimum weight constraints for all days\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame with BTC price data\n",
    "        \n",
    "    Returns:\n",
    "        Series of daily investment weights, summing to 1.0 per market cycle\n",
    "    \"\"\"\n",
    "    # Strategy parameters\n",
    "    REBALANCE_WINDOW = (CYCLE_YEARS*365)//2 \n",
    "    # Redistribute weight from up to 2 years ahead\n",
    "    ALPHA = 1.25  # Multiplier for how much to boost weight based on z-score\n",
    "    \n",
    "    df_work = df.copy()\n",
    "    df_work = construct_features(df)\n",
    "    \n",
    "    # Filter to backtest period only\n",
    "    df_backtest = df_work.loc[BACKTEST_START:BACKTEST_END]\n",
    "    weights = pd.Series(index=df_backtest.index, dtype=float)\n",
    "    \n",
    "    # Group by 4-year market cycles\n",
    "    start_year = pd.to_datetime(BACKTEST_START).year\n",
    "    cycle_labels = df_backtest.index.to_series().apply(lambda dt: (dt.year - start_year) // 4)\n",
    "    \n",
    "    # Process each market cycle separately to maintain weight sum = 1.0 per cycle\n",
    "    for cycle, group in df_backtest.groupby(cycle_labels):\n",
    "        N = len(group)\n",
    "        base_weight = 1.0 / N  # Start with uniform weight distribution\n",
    "        temp_weights = np.full(N, base_weight)\n",
    "        strategy_active = True  # Flag to stop adjustments if constraints can't be met\n",
    "        \n",
    "        # Process each day in the cycle\n",
    "        for i in range(N):\n",
    "            if not strategy_active:\n",
    "                break\n",
    "            \n",
    "            price = group['PriceUSD'].iloc[i]\n",
    "            ma200 = group['ma200'].iloc[i]\n",
    "            std200 = group['std200'].iloc[i]\n",
    "            \n",
    "            # Skip days with insufficient history\n",
    "            if pd.isna(ma200) or pd.isna(std200) or std200 <= 0:\n",
    "                continue\n",
    "            \n",
    "            # Apply weight boost when price is below MA\n",
    "            if price < ma200:\n",
    "                # Calculate z-score (standard deviations below MA)\n",
    "                z = (ma200 - price) / std200\n",
    "                boost_multiplier = 1 + ALPHA * z\n",
    "                current_weight = temp_weights[i]\n",
    "                boosted_weight = current_weight * boost_multiplier\n",
    "                excess = boosted_weight - current_weight\n",
    "                \n",
    "                # Determine which future days to redistribute from\n",
    "                start_redistribution = max(N - REBALANCE_WINDOW, i + 1)\n",
    "                if start_redistribution >= N:\n",
    "                    continue  # No future days to redistribute from\n",
    "                \n",
    "                redistribution_idx = np.arange(start_redistribution, N)\n",
    "                if len(redistribution_idx) == 0:\n",
    "                    continue\n",
    "                    \n",
    "                # Calculate reduction per future day\n",
    "                reduction = excess / len(redistribution_idx)\n",
    "                projected = temp_weights[redistribution_idx] - reduction\n",
    "                \n",
    "                # Only apply changes if minimum weight constraint is satisfied\n",
    "                if np.all(projected >= MIN_WEIGHT):\n",
    "                    temp_weights[i] = boosted_weight\n",
    "                    temp_weights[redistribution_idx] -= reduction\n",
    "                else:\n",
    "                    # Stop strategy adjustments if constraints can't be met\n",
    "                    strategy_active = False\n",
    "        \n",
    "        # Assign weights back to the original index\n",
    "        weights.loc[group.index] = temp_weights\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def compute_weights(df: pd.DataFrame, *, cycle_years: int = CYCLE_YEARS) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Dynamic-DCA weights based on 200-day MA distance.\n",
    "    Sums to 1 **within each `cycle_years` block**.\n",
    "    \"\"\"\n",
    "    # â”€â”€ params â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    REBALANCE_WINDOW = max(int(cycle_years * 365) // 2, 1)   # half the cycle\n",
    "    ALPHA            = 1.25\n",
    "    # â”€â”€ features â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    df_feat   = construct_features(df).loc[BACKTEST_START:BACKTEST_END]\n",
    "    weights   = pd.Series(index=df_feat.index, dtype=float)\n",
    "\n",
    "    start_year   = pd.to_datetime(BACKTEST_START).year\n",
    "    cycle_labels = df_feat.index.to_series().apply(\n",
    "        lambda ts: (ts.year - start_year) // cycle_years\n",
    "    )\n",
    "\n",
    "    # â”€â”€ loop over cycles â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    for _, cycle_df in df_feat.groupby(cycle_labels):\n",
    "        N           = len(cycle_df)\n",
    "        base_wt     = 1.0 / N\n",
    "        temp_wt     = np.full(N, base_wt)\n",
    "\n",
    "        for day in range(N):\n",
    "            price, ma, sd = (\n",
    "                cycle_df[\"PriceUSD\"].iat[day],\n",
    "                cycle_df[\"ma200\"].iat[day],\n",
    "                cycle_df[\"std200\"].iat[day],\n",
    "            )\n",
    "            if pd.isna(ma) or pd.isna(sd) or sd == 0 or price >= ma:\n",
    "                continue\n",
    "\n",
    "            z         = (ma - price) / sd\n",
    "            boosted   = temp_wt[day] * (1 + ALPHA * z)\n",
    "            excess    = boosted - temp_wt[day]\n",
    "\n",
    "            # redistribute from the **last part of the SAME cycle**\n",
    "            start_r   = max(N - REBALANCE_WINDOW, day + 1)\n",
    "            idx_r     = np.arange(start_r, N)\n",
    "            if len(idx_r) == 0:\n",
    "                continue\n",
    "            reduction = excess / len(idx_r)\n",
    "            if np.all(temp_wt[idx_r] - reduction >= MIN_WEIGHT):\n",
    "                temp_wt[day]          = boosted\n",
    "                temp_wt[idx_r]       -= reduction\n",
    "\n",
    "        weights.loc[cycle_df.index] = temp_wt\n",
    "\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75ca490-39e4-4328-ad80-16975dcbd37a",
   "metadata": {},
   "source": [
    "### ğŸš« Boilerplate Code â€” Do Not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1962248-b8a9-466c-8883-d1b64e5de83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_df = load_data()\n",
    "validate_price_data(btc_df)\n",
    "btc_df = btc_df.loc[BACKTEST_START:BACKTEST_END]\n",
    "\n",
    "weights = compute_weights(btc_df)\n",
    "\n",
    "plot_features(df, weights=weights, start_date=BACKTEST_START, end_date=BACKTEST_END)\n",
    "plot_final_weights(weights, start_date=BACKTEST_START)\n",
    "plot_weight_sums_by_cycle(weights)\n",
    "\n",
    "df_spd = backtest_dynamic_dca(btc_df, strategy_fn=compute_weights, strategy_label=\"compute_weights\")\n",
    "check_strategy_submission_ready(btc_df, strategy_fn=compute_weights)\n",
    "plot_spd_comparison(df_spd, strategy_name=\"200 Day MA DCA\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniconda3-stacking-sats-env]",
   "language": "python",
   "name": "conda-env-miniconda3-stacking-sats-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
